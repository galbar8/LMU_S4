{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ETTS Time-Series Forecasting with LMU\n",
    "\n",
    "Train LMU model on Electricity Transformer Temperature (ETT) dataset."
   ],
   "id": "d79455946dbc48ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from __future__ import annotations\n",
    "from typing import Tuple, Dict, Any\n",
    "from torch.utils.data import DataLoader\n",
    "from src.types.task_protocol import TaskProtocol\n",
    "from src.datasets.etts.etts_dataloader import make_etts_loaders\n",
    "\n",
    "class ETTSTask(TaskProtocol):\n",
    "    problem_type: str = \"regression\"\n",
    "\n",
    "    def make_loaders(self, data_root: str, batch_size: int = 64, num_workers: int = 4, **kwargs) -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "        return make_etts_loaders(\n",
    "            data_root=data_root,\n",
    "            which=kwargs.get(\"which\", \"ETTh1\"),\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers,\n",
    "            seq_len=kwargs.get(\"seq_len\", 96),\n",
    "            pred_len=kwargs.get(\"pred_len\", 24),\n",
    "            feature_mode=kwargs.get(\"feature_mode\", \"target\"),\n",
    "            target_col=kwargs.get(\"target_col\", \"OT\"),\n",
    "            split_ratio=kwargs.get(\"split_ratio\", (0.7, 0.1, 0.2)),\n",
    "            normalize=kwargs.get(\"normalize\", \"zscore\"),\n",
    "            pin_memory=kwargs.get(\"pin_memory\", True),\n",
    "            persistent_workers=kwargs.get(\"persistent_workers\", False),\n",
    "        )\n",
    "\n",
    "    def infer_input_dim(self, args: Dict[str, Any]) -> int:\n",
    "        fm = args.get(\"feature_mode\", \"target\")\n",
    "        return 1 if fm == \"target_only\" else 7\n",
    "\n",
    "    def infer_num_classes(self, args: Dict[str, Any]) -> int:\n",
    "        return 7 if args.get(\"feature_mode\", \"target\") == \"multivariate\" else 1\n",
    "\n",
    "    def infer_theta(self, args: Dict[str, Any]) -> int:\n",
    "        return args.get(\"seq_len\", 96)\n",
    "\n",
    "def create_block_cfg_ctor(dropout, mlp_ratio, droppath_final, layerscale_init, residual_gain, pool):\n",
    "    from src.models.v2.build_model import BlockConfig\n",
    "    def block_cfg_ctor(theta: int):\n",
    "        return BlockConfig(kind=\"lmu\", memory_size=256, theta=theta, dropout=dropout, mlp_ratio=mlp_ratio,\n",
    "                           droppath_final=droppath_final, layerscale_init=layerscale_init,\n",
    "                           residual_gain=residual_gain, pool=pool)\n",
    "    return block_cfg_ctor\n"
   ],
   "id": "aa6acb5a7033499f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "39e2b2d4a48d014f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent.parent\n",
    "data_root = str(project_root / \"datasets\" / \"etts\" / \"data\")\n",
    "\n",
    "args = {\n",
    "    \"data_root\": data_root,\n",
    "    \"batch\": 64,\n",
    "    \"data_loader_kwargs\": {\n",
    "        \"num_workers\": 0,\n",
    "        \"which\": \"ETTh1\",\n",
    "        \"seq_len\": 96,\n",
    "        \"pred_len\": 24,\n",
    "        \"feature_mode\": \"target\",\n",
    "        \"target_col\": \"OT\",\n",
    "        \"split_ratio\": (0.7, 0.1, 0.2),\n",
    "        \"normalize\": \"zscore\",\n",
    "        \"pin_memory\": False,\n",
    "        \"persistent_workers\": False,\n",
    "    },\n",
    "    \"epochs\": 50,\n",
    "    \"lr\": 1e-3,\n",
    "    \"wd\": 1e-4,\n",
    "    \"amp\": True,\n",
    "    \"save_dir\": \"./runs/etts_task\",\n",
    "    \"warmup_epochs\": 5,\n",
    "    \"patience\": 10,\n",
    "    \"min_delta\": 0.001,\n",
    "    \"d_model\": 256,\n",
    "    \"depth\": 6,\n",
    "    \"dropout\": 0.2,\n",
    "    \"mlp_ratio\": 2.0,\n",
    "    \"droppath_final\": 0.1,\n",
    "    \"layerscale_init\": 1e-2,\n",
    "    \"residual_gain\": 1.0,\n",
    "    \"pool\": \"none\",\n",
    "}\n",
    "\n",
    "args[\"block_cfg_ctor\"] = create_block_cfg_ctor(\n",
    "    dropout=args[\"dropout\"], mlp_ratio=args[\"mlp_ratio\"], droppath_final=args[\"droppath_final\"],\n",
    "    layerscale_init=args[\"layerscale_init\"], residual_gain=args[\"residual_gain\"], pool=args[\"pool\"]\n",
    ")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    args[\"device\"] = torch.device(\"mps\")\n",
    "    print(\"ðŸš€ Using MPS (M4 Neural Engine)\")\n",
    "elif torch.cuda.is_available():\n",
    "    args[\"device\"] = torch.device(\"cuda\")\n",
    "else:\n",
    "    args[\"device\"] = torch.device(\"cpu\")\n",
    "    args[\"amp\"] = False"
   ],
   "id": "4180051b784c4419"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "3950250c3ce6f517"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "770362992a0b377a"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Plot History\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(12, 5))\\n\",\n",
    "    \"plt.subplot(1, 2, 1)\\n\",\n",
    "    \"plt.plot(history[\\\"train_loss\\\"], label=\\\"train_loss\\\")\\n\",\n",
    "    \"plt.plot(history[\\\"val_loss\\\"], label=\\\"val_loss\\\")\\n\",\n",
    "    \"plt.xlabel(\\\"epoch\\\")\\n\",\n",
    "    \"plt.ylabel(\\\"MSE Loss\\\")\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.title(\\\"Training Loss\\\")\\n\",\n",
    "    \"plt.grid(True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.subplot(1, 2, 2)\\n\",\n",
    "    \"plt.plot(history[\\\"train_mae\\\"], label=\\\"train_mae\\\")\\n\",\n",
    "    \"plt.plot(history[\\\"val_mae\\\"], label=\\\"val_mae\\\")\\n\",\n",
    "    \"plt.xlabel(\\\"epoch\\\")\\n\",\n",
    "    \"plt.ylabel(\\\"MAE\\\")\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.title(\\\"Mean Absolute Error\\\")\\n\",\n",
    "    \"plt.grid(True)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Test Evaluation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import numpy as np\\n\",\n",
    "    \"\\n\",\n",
    "    \"def evaluate_test_set():\\n\",\n",
    "    \"    task = ETTSTask()\\n\",\n",
    "    \"    _, _, test_loader = task.make_loaders(data_root=args[\\\"data_root\\\"], batch_size=args[\\\"batch\\\"], \\n\",\n",
    "    \"                                          **args[\\\"data_loader_kwargs\\\"])\\n\",\n",
    "    \"    checkpoint = torch.load(best_path, map_location=args[\\\"device\\\"])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    flat_args = dict(args)\\n\",\n",
    "    \"    flat_args.update(args.get(\\\"data_loader_kwargs\\\", {}))\\n\",\n",
    "    \"    d_in = task.infer_input_dim(flat_args)\\n\",\n",
    "    \"    d_out = task.infer_num_classes(flat_args)\\n\",\n",
    "    \"    theta = task.infer_theta(flat_args)\\n\",\n",
    "    \"    pred_len = flat_args.get(\\\"pred_len\\\", 24)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    block_cfg = args[\\\"block_cfg_ctor\\\"](theta)\\n\",\n",
    "    \"    model = build_model(d_in=d_in, n_classes=d_out * pred_len, d_model=args[\\\"d_model\\\"],\\n\",\n",
    "    \"                        depth=args[\\\"depth\\\"], block_cfg=block_cfg).to(args[\\\"device\\\"])\\n\",\n",
    "    \"    model.load_state_dict(checkpoint[\\\"model\\\"])\\n\",\n",
    "    \"    model.eval()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"Loaded checkpoint from epoch {checkpoint['epoch']}\\\")\\n\",\n",
    "    \"    print(f\\\"Val loss: {checkpoint['val_loss']:.6f}, Val MAE: {checkpoint['val_mae']:.6f}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    test_loss = test_mae = 0.0\\n\",\n",
    "    \"    criterion = nn.MSELoss()\\n\",\n",
    "    \"    device_type = args[\\\"device\\\"].type\\n\",\n",
    "    \"    amp = args.get(\\\"amp\\\", False) and device_type in {\\\"cuda\\\", \\\"mps\\\"}\\n\",\n",
    "    \"    all_preds, all_targets = [], []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    with torch.no_grad():\\n\",\n",
    "    \"        for x, y in tqdm(test_loader, desc=\\\"Testing\\\"):\\n\",\n",
    "    \"            x, y = x.to(args[\\\"device\\\"]), y.to(args[\\\"device\\\"])\\n\",\n",
    "    \"            with amp_autocast(amp):\\n\",\n",
    "    \"                out = model(x).view(x.size(0), pred_len, d_out)\\n\",\n",
    "    \"                loss = criterion(out, y)\\n\",\n",
    "    \"            test_loss += loss.item()\\n\",\n",
    "    \"            test_mae += torch.abs(out - y).mean().item()\\n\",\n",
    "    \"            all_preds.append(out.cpu().numpy())\\n\",\n",
    "    \"            all_targets.append(y.cpu().numpy())\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    test_loss /= len(test_loader)\\n\",\n",
    "    \"    test_mae /= len(test_loader)\\n\",\n",
    "    \"    all_preds = np.concatenate(all_preds, axis=0)\\n\",\n",
    "    \"    all_targets = np.concatenate(all_targets, axis=0)\\n\",\n",
    "    \"    test_rmse = np.sqrt(test_loss)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"\\\\n\\\" + \\\"=\\\"*50)\\n\",\n",
    "    \"    print(\\\"TEST SET RESULTS:\\\")\\n\",\n",
    "    \"    print(\\\"=\\\"*50)\\n\",\n",
    "    \"    print(f\\\"MSE:  {test_loss:.6f}\\\")\\n\",\n",
    "    \"    print(f\\\"MAE:  {test_mae:.6f}\\\")\\n\",\n",
    "    \"    print(f\\\"RMSE: {test_rmse:.6f}\\\")\\n\",\n",
    "    \"    return all_preds, all_targets\\n\",\n",
    "    \"\\n\",\n",
    "    \"preds, targets = evaluate_test_set()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Visualize Predictions\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"num_examples = 4\\n\",\n",
    "    \"fig, axes = plt.subplots(num_examples, 1, figsize=(12, 3 * num_examples))\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i in range(num_examples):\\n\",\n",
    "    \"    ax = axes[i] if num_examples > 1 else axes\\n\",\n",
    "    \"    target_seq = targets[i, :, 0]\\n\",\n",
    "    \"    pred_seq = preds[i, :, 0]\\n\",\n",
    "    \"    timesteps = range(len(target_seq))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    ax.plot(timesteps, target_seq, 'b-', label='Ground Truth', linewidth=2)\\n\",\n",
    "    \"    ax.plot(timesteps, pred_seq, 'r--', label='Prediction', linewidth=2)\\n\",\n",
    "    \"    ax.set_xlabel('Time Step')\\n\",\n",
    "    \"    ax.set_ylabel('Value')\\n\",\n",
    "    \"    ax.set_title(f'Example {i+1}: Prediction vs Ground Truth')\\n\",\n",
    "    \"    ax.legend()\\n\",\n",
    "    \"    ax.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}\n",
    "\n"
   ],
   "id": "e4bd828df57499ed",
   "outputs": null,
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "70356eb9f1ea6cee"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
