{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ETTS Time-Series Forecasting with S4 (Agnostic Flow)\n",
    "\n",
    "Train S4 model on Electricity Transformer Temperature (ETT) dataset using the same task-agnostic trainer and evaluation flow as LMU. The configuration is kept generic so we can swap LMU/S4 easily for fair comparison."
   ],
   "id": "4d137d21be989597"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T13:36:36.785711Z",
     "start_time": "2025-11-15T13:36:34.699905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from __future__ import annotations\n",
    "from typing import Dict, Any\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from src.notebooks.etts.utils import ETTSTask, make_block_cfg_ctor, evaluate_best_model"
   ],
   "id": "bbd2c936f8ce20ca",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.\n",
      "Falling back on slow Cauchy and Vandermonde kernel. Install at least one of pykeops or the CUDA extension for better speed and memory efficiency.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "329127508e93dcc0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T13:36:39.954376Z",
     "start_time": "2025-11-15T13:36:39.936751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent.parent.parent\n",
    "data_root = str(project_root / \"src\" / \"datasets\" / \"etts\" / \"data\")\n",
    "\n",
    "# S4-specific base parameters\n",
    "s4_base_params = {\n",
    "    \"d_state\": 64,\n",
    "    \"channels\": 1,\n",
    "    \"bidirectional\": False,  # Causal for forecasting\n",
    "    \"mode\": \"s4d\",\n",
    "    \"dt_min\": 1e-3,\n",
    "    \"dt_max\": 1e-1,\n",
    "}\n",
    "\n",
    "# --- Agnostic Configurations for each ETT Dataset ---\n",
    "\n",
    "etth1_config_s4 = {\n",
    "    \"data_root\": data_root,\n",
    "    \"batch\": 64,\n",
    "    \"epochs\": 50,\n",
    "    \"lr\": 1e-4,\n",
    "    \"wd\": 1e-3,\n",
    "    \"amp\": True,\n",
    "    \"save_dir\": \"./runs/etts_s4_task_h1\",\n",
    "    \"warmup_epochs\": 5,\n",
    "    \"patience\": 10,\n",
    "    \"min_delta\": 0.001,\n",
    "    \"d_model\": 256,\n",
    "    \"depth\": 6,\n",
    "    \"dropout\": 0.3,\n",
    "    \"mlp_ratio\": 2.0,\n",
    "    \"droppath_final\": 0.1,\n",
    "    \"layerscale_init\": 1e-2,\n",
    "    \"residual_gain\": 1.0,\n",
    "    \"pool\": \"none\",\n",
    "    \"data_loader_kwargs\": {\n",
    "        \"num_workers\": 0,\n",
    "        \"which\": \"ETTh1\",\n",
    "        \"seq_len\": 96,\n",
    "        \"pred_len\": 24,\n",
    "        \"feature_mode\": \"target\",\n",
    "        \"target_col\": \"OT\",\n",
    "        \"split_ratio\": (0.7, 0.1, 0.2),\n",
    "        \"normalize\": \"zscore\",\n",
    "        \"pin_memory\": False,\n",
    "        \"persistent_workers\": False,\n",
    "    },\n",
    "    **s4_base_params\n",
    "}\n",
    "\n",
    "etth2_config_s4 = {\n",
    "    \"data_root\": data_root,\n",
    "    \"batch\": 64,\n",
    "    \"epochs\": 50,\n",
    "    \"lr\": 1e-4,\n",
    "    \"wd\": 2e-3,\n",
    "    \"amp\": True,\n",
    "    \"save_dir\": \"./runs/etts_s4_task_h2\",\n",
    "    \"warmup_epochs\": 5,\n",
    "    \"patience\": 10,\n",
    "    \"min_delta\": 0.001,\n",
    "    \"d_model\": 256,\n",
    "    \"depth\": 4,\n",
    "    \"dropout\": 0.3,\n",
    "    \"mlp_ratio\": 2.0,\n",
    "    \"droppath_final\": 0.1,\n",
    "    \"layerscale_init\": 1e-2,\n",
    "    \"residual_gain\": 1.0,\n",
    "    \"pool\": \"none\",\n",
    "    \"data_loader_kwargs\": {\n",
    "        \"num_workers\": 0,\n",
    "        \"which\": \"ETTh2\",\n",
    "        \"seq_len\": 96,\n",
    "        \"pred_len\": 24,\n",
    "        \"feature_mode\": \"target\",\n",
    "        \"target_col\": \"OT\",\n",
    "        \"split_ratio\": (0.7, 0.1, 0.2),\n",
    "        \"normalize\": \"zscore\",\n",
    "        \"pin_memory\": False,\n",
    "        \"persistent_workers\": False,\n",
    "    },\n",
    "    **s4_base_params\n",
    "}\n",
    "\n",
    "ettm1_config_s4 = {\n",
    "    \"data_root\": data_root,\n",
    "    \"batch\": 64,\n",
    "    \"epochs\": 50,\n",
    "    \"lr\": 1e-4,\n",
    "    \"wd\": 2e-3,\n",
    "    \"amp\": True,\n",
    "    \"save_dir\": \"./runs/etts_s4_task_m1\",\n",
    "    \"warmup_epochs\": 5,\n",
    "    \"patience\": 10,\n",
    "    \"min_delta\": 0.001,\n",
    "    \"d_model\": 256,\n",
    "    \"depth\": 4,\n",
    "    \"dropout\": 0.3,\n",
    "    \"mlp_ratio\": 2.0,\n",
    "    \"droppath_final\": 0.1,\n",
    "    \"layerscale_init\": 1e-2,\n",
    "    \"residual_gain\": 1.0,\n",
    "    \"pool\": \"none\",\n",
    "    \"data_loader_kwargs\": {\n",
    "        \"num_workers\": 0,\n",
    "        \"which\": \"ETTm1\",\n",
    "        \"seq_len\": 96,\n",
    "        \"pred_len\": 24,\n",
    "        \"feature_mode\": \"target\",\n",
    "        \"target_col\": \"OT\",\n",
    "        \"split_ratio\": (0.7, 0.1, 0.2),\n",
    "        \"normalize\": \"zscore\",\n",
    "        \"pin_memory\": False,\n",
    "        \"persistent_workers\": False,\n",
    "    },\n",
    "    **s4_base_params\n",
    "}\n",
    "\n",
    "ettm2_config_s4 = {\n",
    "    \"data_root\": data_root,\n",
    "    \"batch\": 64,\n",
    "    \"epochs\": 50,\n",
    "    \"lr\": 1e-4,\n",
    "    \"wd\": 2e-3,\n",
    "    \"amp\": True,\n",
    "    \"save_dir\": \"./runs/etts_s4_task_m2\",\n",
    "    \"warmup_epochs\": 5,\n",
    "    \"patience\": 10,\n",
    "    \"min_delta\": 0.001,\n",
    "    \"d_model\": 256,\n",
    "    \"depth\": 4,\n",
    "    \"dropout\": 0.3,\n",
    "    \"mlp_ratio\": 2.0,\n",
    "    \"droppath_final\": 0.1,\n",
    "    \"layerscale_init\": 1e-2,\n",
    "    \"residual_gain\": 1.0,\n",
    "    \"pool\": \"none\",\n",
    "    \"data_loader_kwargs\": {\n",
    "        \"num_workers\": 0,\n",
    "        \"which\": \"ETTm2\",\n",
    "        \"seq_len\": 96,\n",
    "        \"pred_len\": 24,\n",
    "        \"feature_mode\": \"target\",\n",
    "        \"target_col\": \"OT\",\n",
    "        \"split_ratio\": (0.7, 0.1, 0.2),\n",
    "        \"normalize\": \"zscore\",\n",
    "        \"pin_memory\": False,\n",
    "        \"persistent_workers\": False,\n",
    "    },\n",
    "    **s4_base_params\n",
    "}\n",
    "\n",
    "args: Dict[str, Any] = ettm1_config_s4\n",
    "print(f\"Training S4 on: {args['data_loader_kwargs']['which']}\")\n",
    "\n",
    "\n",
    "# Agnostic: swap kind between \"s4\" and \"lmu\" to compare\n",
    "args[\"block_cfg_ctor\"] = make_block_cfg_ctor(\n",
    "    kind=\"s4\",\n",
    "    dropout=args[\"dropout\"],\n",
    "    mlp_ratio=args[\"mlp_ratio\"],\n",
    "    droppath_final=args[\"droppath_final\"],\n",
    "    layerscale_init=args[\"layerscale_init\"],\n",
    "    residual_gain=args[\"residual_gain\"],\n",
    "    pool=args[\"pool\"],\n",
    "    # LMU\n",
    "    memory_size=256,\n",
    "    # S4\n",
    "    d_state=args[\"d_state\"],\n",
    "    channels=args[\"channels\"],\n",
    "    bidirectional=args[\"bidirectional\"],\n",
    "    mode=args[\"mode\"],\n",
    "    dt_min=args[\"dt_min\"],\n",
    "    dt_max=args[\"dt_max\"],\n",
    ")\n",
    "\n",
    "# Device selection (MPS first)\n",
    "if torch.backends.mps.is_available():\n",
    "    args[\"device\"] = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Apple Silicon)\")\n",
    "elif torch.cuda.is_available():\n",
    "    args[\"device\"] = torch.device(\"cuda\")\n",
    "else:\n",
    "    args[\"device\"] = torch.device(\"cpu\")\n",
    "    args[\"amp\"] = False\n"
   ],
   "id": "b5f8756c6c6a7e4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training S4 on: ETTm1\n",
      "Using MPS (Apple Silicon)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "ec0aad16c4028334"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-15T13:36:57.798984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.train_utils.trainer import Trainer\n",
    "from src.models.v2.build_model import build_model\n",
    "import os\n",
    "\n",
    "# Define the task\n",
    "task = ETTSTask()\n",
    "\n",
    "# MPS memory options if available\n",
    "if args.get(\"device\") and args[\"device\"].type == \"mps\":\n",
    "    torch.mps.set_per_process_memory_fraction(0.9)\n",
    "    os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
    "\n",
    "trainer = Trainer(args=args, task=task, model_builder=build_model)\n",
    "\n",
    "best_metric, best_path = trainer.fit()\n",
    "\n",
    "history = trainer.history\n",
    "\n",
    "print(f\"\\nTraining complete! Best validation {trainer.early_key}: {best_metric:.6f}\")\n",
    "print(f\"Best model saved to: {best_path}\")\n"
   ],
   "id": "74aaac7da0320131",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/glbrlb/PycharmProjects/Msc/LMU_S4/src/models/s4/s4_block.py:322: RuntimeWarning: divide by zero encountered in matmul\n",
      "  A = T @ M @ np.linalg.inv(T)\n",
      "/Users/glbrlb/PycharmProjects/Msc/LMU_S4/src/models/s4/s4_block.py:322: RuntimeWarning: overflow encountered in matmul\n",
      "  A = T @ M @ np.linalg.inv(T)\n",
      "/Users/glbrlb/PycharmProjects/Msc/LMU_S4/src/models/s4/s4_block.py:322: RuntimeWarning: invalid value encountered in matmul\n",
      "  A = T @ M @ np.linalg.inv(T)\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ saved best model to ./runs/etts_s4_task_m1/best.pt\n",
      "âœ… new best mse 2.5395\n",
      "Epoch 000/50 | train 1.2114/1.2114 | val 2.5395/2.5395 | t 118.5s/7.6s | lr 1.00e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  18%|â–ˆâ–Š        | 134/760 [00:21<01:40,  6.21it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plot History",
   "id": "85fd82926cf85204"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Loss\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history[\"train_mae\"], label=\"train_mae\")\n",
    "plt.plot(history[\"val_mae\"], label=\"val_mae\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "plt.title(\"Mean Absolute Error\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "4a8090fb744d8e71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test Evaluation",
   "id": "73dea442fd3b4f1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.models.v2.build_model import build_model\n",
    "\n",
    "preds, targets = evaluate_best_model(\n",
    "    args=args,\n",
    "    task=task,\n",
    "    model_builder=build_model,\n",
    "    best_model_path=best_path,\n",
    ")"
   ],
   "id": "422b7749f5ee79e7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
